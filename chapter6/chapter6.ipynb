{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning System With Python - Chapter 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01_start.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: .\\data\\rawdata\\126131070050639874.json, error: No JSON object could be decoded\n",
      "file: .\\data\\rawdata\\126111632773480448.json, error: No JSON object could be decoded\n",
      "#irrelevant: 95\n",
      "#negative: 288\n",
      "#neutral: 609\n",
      "#positive: 194\n",
      "== Pos vs. neg ==\n",
      "0.731\t0.029\t0.888\t0.033\t\n",
      "== Pos/neg vs. irrelevant/neutral ==\n",
      "0.746\t0.018\t0.798\t0.031\t\n",
      "== Pos vs. rest ==\n",
      "0.842\t0.011\t0.544\t0.051\t\n",
      "== Neg vs. rest ==\n",
      "0.770\t0.020\t0.665\t0.039\t\n",
      "('time spent:', 13.01799988746643)\n"
     ]
    }
   ],
   "source": [
    "# This code is supporting material for the book\n",
    "# Building Machine Learning Systems with Python\n",
    "# by Willi Richert and Luis Pedro Coelho\n",
    "# published by PACKT Publishing\n",
    "#\n",
    "# It is made available under the MIT License\n",
    "\n",
    "#\n",
    "# This script trains multinomial Naive Bayes on the tweet corpus\n",
    "# to find two different results:\n",
    "# - How well can we distinguis positive from negative tweets?\n",
    "# - How well can we detect whether a tweet contains sentiment at all?\n",
    "#\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "from utils import plot_pr\n",
    "from utils import load_sanders_data\n",
    "from utils import tweak_labels\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "def create_ngram_model():\n",
    "    tfidf_ngrams = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                                   analyzer=\"word\", binary=False)\n",
    "    clf = MultinomialNB()\n",
    "    pipeline = Pipeline([('vect', tfidf_ngrams), ('clf', clf)])\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def train_model(clf_factory, X, Y, name=\"NB ngram\", plot=False):\n",
    "    cv = ShuffleSplit(\n",
    "        n=len(X), n_iter=10, test_size=0.3, random_state=0)\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "\n",
    "    scores = []\n",
    "    pr_scores = []\n",
    "    precisions, recalls, thresholds = [], [], []\n",
    "\n",
    "    for train, test in cv:\n",
    "        X_train, y_train = X[train], Y[train]\n",
    "        X_test, y_test = X[test], Y[test]\n",
    "\n",
    "        clf = clf_factory()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        test_score = clf.score(X_test, y_test)\n",
    "\n",
    "        train_errors.append(1 - train_score)\n",
    "        test_errors.append(1 - test_score)\n",
    "\n",
    "        scores.append(test_score)\n",
    "        proba = clf.predict_proba(X_test)\n",
    "\n",
    "        fpr, tpr, roc_thresholds = roc_curve(y_test, proba[:, 1])\n",
    "        precision, recall, pr_thresholds = precision_recall_curve(\n",
    "            y_test, proba[:, 1])\n",
    "\n",
    "        pr_scores.append(auc(recall, precision))\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        thresholds.append(pr_thresholds)\n",
    "\n",
    "    scores_to_sort = pr_scores\n",
    "    median = np.argsort(scores_to_sort)[len(scores_to_sort) / 2]\n",
    "\n",
    "    if plot:\n",
    "        plot_pr(pr_scores[median], name, \"01\", precisions[median],\n",
    "                recalls[median], label=name)\n",
    "\n",
    "        summary = (np.mean(scores), np.std(scores),\n",
    "                   np.mean(pr_scores), np.std(pr_scores))\n",
    "        print(\"%.3f\\t%.3f\\t%.3f\\t%.3f\\t\" % summary)\n",
    "\n",
    "    return np.mean(train_errors), np.mean(test_errors)\n",
    "\n",
    "\n",
    "def print_incorrect(clf, X, Y):\n",
    "    Y_hat = clf.predict(X)\n",
    "    wrong_idx = Y_hat != Y\n",
    "    X_wrong = X[wrong_idx]\n",
    "    Y_wrong = Y[wrong_idx]\n",
    "    Y_hat_wrong = Y_hat[wrong_idx]\n",
    "    for idx in range(len(X_wrong)):\n",
    "        print(\"clf.predict('%s')=%i instead of %i\" %\n",
    "              (X_wrong[idx], Y_hat_wrong[idx], Y_wrong[idx]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_orig, Y_orig = load_sanders_data()\n",
    "    classes = np.unique(Y_orig)\n",
    "    for c in classes:\n",
    "        print(\"#%s: %i\" % (c, sum(Y_orig == c)))\n",
    "\n",
    "    print(\"== Pos vs. neg ==\")\n",
    "    pos_neg = np.logical_or(Y_orig == \"positive\", Y_orig == \"negative\")\n",
    "    X = X_orig[pos_neg]\n",
    "    Y = Y_orig[pos_neg]\n",
    "    Y = tweak_labels(Y, [\"positive\"])\n",
    "\n",
    "    train_model(create_ngram_model, X, Y, name=\"pos vs neg\", plot=True)\n",
    "\n",
    "    print(\"== Pos/neg vs. irrelevant/neutral ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"positive\", \"negative\"])\n",
    "    train_model(create_ngram_model, X, Y, name=\"sent vs rest\", plot=True)\n",
    "\n",
    "    print(\"== Pos vs. rest ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"positive\"])\n",
    "    train_model(create_ngram_model, X, Y, name=\"pos vs rest\", plot=True)\n",
    "\n",
    "    print(\"== Neg vs. rest ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"negative\"])\n",
    "    train_model(create_ngram_model, X, Y, name=\"neg vs rest\", plot=True)\n",
    "\n",
    "    print(\"time spent:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02_tuning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: .\\data\\rawdata\\126131070050639874.json, error: No JSON object could be decoded\n",
      "file: .\\data\\rawdata\\126111632773480448.json, error: No JSON object could be decoded\n",
      "#irrelevant: 95\n",
      "#negative: 288\n",
      "#neutral: 609\n",
      "#positive: 194\n",
      "== Pos vs. neg ==\n",
      "0.826\t0.032\t0.886\t0.027\t\n",
      "== Pos/neg vs. irrelevant/neutral ==\n",
      "0.750\t0.011\t0.788\t0.030\t\n",
      "== Pos vs. rest ==\n",
      "0.887\t0.011\t0.665\t0.053\t\n",
      "== Neg vs. rest ==\n",
      "0.821\t0.017\t0.701\t0.046\t\n",
      "('time spent:', 6.7840001583099365)\n"
     ]
    }
   ],
   "source": [
    "# This code is supporting material for the book\n",
    "# Building Machine Learning Systems with Python\n",
    "# by Willi Richert and Luis Pedro Coelho\n",
    "# published by PACKT Publishing\n",
    "#\n",
    "# It is made available under the MIT License\n",
    "\n",
    "#\n",
    "# This script trains tries to tweak hyperparameters to improve P/R AUC\n",
    "#\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "from utils import plot_pr\n",
    "from utils import load_sanders_data\n",
    "from utils import tweak_labels\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "phase = \"02\"\n",
    "\n",
    "\n",
    "def create_ngram_model(params=None):\n",
    "    tfidf_ngrams = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                                   analyzer=\"word\", binary=False)\n",
    "    clf = MultinomialNB()\n",
    "    pipeline = Pipeline([('vect', tfidf_ngrams), ('clf', clf)])\n",
    "\n",
    "    if params:\n",
    "        pipeline.set_params(**params)\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def grid_search_model(clf_factory, X, Y):\n",
    "    cv = ShuffleSplit(\n",
    "        n=len(X), n_iter=10, test_size=0.3, random_state=0)\n",
    "\n",
    "    param_grid = dict(vect__ngram_range=[(1, 1), (1, 2), (1, 3)],\n",
    "                      vect__min_df=[1, 2],\n",
    "                      vect__stop_words=[None, \"english\"],\n",
    "                      vect__smooth_idf=[False, True],\n",
    "                      vect__use_idf=[False, True],\n",
    "                      vect__sublinear_tf=[False, True],\n",
    "                      vect__binary=[False, True],\n",
    "                      clf__alpha=[0, 0.01, 0.05, 0.1, 0.5, 1],\n",
    "                      )\n",
    "\n",
    "    grid_search = GridSearchCV(clf_factory(),\n",
    "                               param_grid=param_grid,\n",
    "                               cv=cv,\n",
    "                               score_func=f1_score,\n",
    "                               verbose=10)\n",
    "    grid_search.fit(X, Y)\n",
    "    clf = grid_search.best_estimator_\n",
    "    print(clf)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_model(clf, X, Y, name=\"NB ngram\", plot=False):\n",
    "    # create it again for plotting\n",
    "    cv = ShuffleSplit(\n",
    "        n=len(X), n_iter=10, test_size=0.3, random_state=0)\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "\n",
    "    scores = []\n",
    "    pr_scores = []\n",
    "    precisions, recalls, thresholds = [], [], []\n",
    "\n",
    "    for train, test in cv:\n",
    "        X_train, y_train = X[train], Y[train]\n",
    "        X_test, y_test = X[test], Y[test]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        test_score = clf.score(X_test, y_test)\n",
    "\n",
    "        train_errors.append(1 - train_score)\n",
    "        test_errors.append(1 - test_score)\n",
    "\n",
    "        scores.append(test_score)\n",
    "        proba = clf.predict_proba(X_test)\n",
    "\n",
    "        fpr, tpr, roc_thresholds = roc_curve(y_test, proba[:, 1])\n",
    "        precision, recall, pr_thresholds = precision_recall_curve(\n",
    "            y_test, proba[:, 1])\n",
    "\n",
    "        pr_scores.append(auc(recall, precision))\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        thresholds.append(pr_thresholds)\n",
    "\n",
    "    if plot:\n",
    "        scores_to_sort = pr_scores\n",
    "        median = np.argsort(scores_to_sort)[len(scores_to_sort) / 2]\n",
    "\n",
    "        plot_pr(pr_scores[median], name, phase, precisions[median],\n",
    "                recalls[median], label=name)\n",
    "\n",
    "    summary = (np.mean(scores), np.std(scores),\n",
    "               np.mean(pr_scores), np.std(pr_scores))\n",
    "    print(\"%.3f\\t%.3f\\t%.3f\\t%.3f\\t\" % summary)\n",
    "\n",
    "    return np.mean(train_errors), np.mean(test_errors)\n",
    "\n",
    "\n",
    "def print_incorrect(clf, X, Y):\n",
    "    Y_hat = clf.predict(X)\n",
    "    wrong_idx = Y_hat != Y\n",
    "    X_wrong = X[wrong_idx]\n",
    "    Y_wrong = Y[wrong_idx]\n",
    "    Y_hat_wrong = Y_hat[wrong_idx]\n",
    "    for idx in range(len(X_wrong)):\n",
    "        print(\"clf.predict('%s')=%i instead of %i\" %\n",
    "              (X_wrong[idx], Y_hat_wrong[idx], Y_wrong[idx]))\n",
    "\n",
    "\n",
    "def get_best_model():\n",
    "    best_params = dict(vect__ngram_range=(1, 2),\n",
    "                       vect__min_df=1,\n",
    "                       vect__stop_words=None,\n",
    "                       vect__smooth_idf=False,\n",
    "                       vect__use_idf=False,\n",
    "                       vect__sublinear_tf=True,\n",
    "                       vect__binary=False,\n",
    "                       clf__alpha=0.01,\n",
    "                       )\n",
    "\n",
    "    best_clf = create_ngram_model(best_params)\n",
    "\n",
    "    return best_clf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_orig, Y_orig = load_sanders_data()\n",
    "    classes = np.unique(Y_orig)\n",
    "    for c in classes:\n",
    "        print(\"#%s: %i\" % (c, sum(Y_orig == c)))\n",
    "\n",
    "    print(\"== Pos vs. neg ==\")\n",
    "    pos_neg = np.logical_or(Y_orig == \"positive\", Y_orig == \"negative\")\n",
    "    X = X_orig[pos_neg]\n",
    "    Y = Y_orig[pos_neg]\n",
    "    Y = tweak_labels(Y, [\"positive\"])\n",
    "    train_model(get_best_model(), X, Y, name=\"pos vs neg\", plot=True)\n",
    "\n",
    "    print(\"== Pos/neg vs. irrelevant/neutral ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"positive\", \"negative\"])\n",
    "\n",
    "    # best_clf = grid_search_model(create_ngram_model, X, Y, name=\"sent vs\n",
    "    # rest\", plot=True)\n",
    "    train_model(get_best_model(), X, Y, name=\"pos vs neg\", plot=True)\n",
    "\n",
    "    print(\"== Pos vs. rest ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"positive\"])\n",
    "    train_model(get_best_model(), X, Y, name=\"pos vs rest\",\n",
    "                plot=True)\n",
    "\n",
    "    print(\"== Neg vs. rest ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"negative\"])\n",
    "    train_model(get_best_model(), X, Y, name=\"neg vs rest\",\n",
    "                plot=True)\n",
    "\n",
    "    print(\"time spent:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03_clean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: .\\data\\rawdata\\126131070050639874.json, error: No JSON object could be decoded\n",
      "file: .\\data\\rawdata\\126111632773480448.json, error: No JSON object could be decoded\n",
      "#irrelevant: 95\n",
      "#negative: 288\n",
      "#neutral: 609\n",
      "#positive: 194\n",
      "== Pos vs. neg ==\n",
      "0.831\t0.034\t0.896\t0.028\t\n",
      "== Pos/neg vs. irrelevant/neutral ==\n",
      "0.749\t0.010\t0.791\t0.028\t\n",
      "== Pos vs. rest ==\n",
      "0.888\t0.010\t0.671\t0.053\t\n",
      "== Neg vs. rest ==\n",
      "0.819\t0.011\t0.703\t0.045\t\n",
      "('time spent:', 16.937999963760376)\n"
     ]
    }
   ],
   "source": [
    "# This code is supporting material for the book\n",
    "# Building Machine Learning Systems with Python\n",
    "# by Willi Richert and Luis Pedro Coelho\n",
    "# published by PACKT Publishing\n",
    "#\n",
    "# It is made available under the MIT License\n",
    "\n",
    "#\n",
    "# This script tries to improve the classifier by cleaning the tweets a bit\n",
    "#\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from utils import plot_pr\n",
    "from utils import load_sanders_data\n",
    "from utils import tweak_labels\n",
    "from utils import log_false_positives\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from utils import load_sent_word_net\n",
    "\n",
    "sent_word_net = load_sent_word_net()\n",
    "\n",
    "phase = \"03\"\n",
    "\n",
    "emo_repl = {\n",
    "    # positive emoticons\n",
    "    \"&lt;3\": \" good \",\n",
    "    \":d\": \" good \",  # :D in lower case\n",
    "    \":dd\": \" good \",  # :DD in lower case\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "\n",
    "    # negative emoticons:\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":S\": \" bad \",\n",
    "    \":-S\": \" bad \",\n",
    "}\n",
    "\n",
    "emo_repl_order = [k for (k_len, k) in reversed(\n",
    "    sorted([(len(k), k) for k in list(emo_repl.keys())]))]\n",
    "\n",
    "re_repl = {\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "}\n",
    "\n",
    "\n",
    "def create_ngram_model(params=None):\n",
    "    def preprocessor(tweet):\n",
    "        global emoticons_replaced\n",
    "        tweet = tweet.lower()\n",
    "\n",
    "        for k in emo_repl_order:\n",
    "            tweet = tweet.replace(k, emo_repl[k])\n",
    "        for r, repl in re_repl.items():\n",
    "            tweet = re.sub(r, repl, tweet)\n",
    "\n",
    "        return tweet\n",
    "\n",
    "    tfidf_ngrams = TfidfVectorizer(preprocessor=preprocessor,\n",
    "                                   analyzer=\"word\")\n",
    "    clf = MultinomialNB()\n",
    "    pipeline = Pipeline([('tfidf', tfidf_ngrams), ('clf', clf)])\n",
    "\n",
    "    if params:\n",
    "        pipeline.set_params(**params)\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def train_model(clf, X, Y, name=\"NB ngram\", plot=False):\n",
    "    # create it again for plotting\n",
    "    cv = ShuffleSplit(\n",
    "        n=len(X), n_iter=10, test_size=0.3, random_state=0)\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "\n",
    "    scores = []\n",
    "    pr_scores = []\n",
    "    precisions, recalls, thresholds = [], [], []\n",
    "\n",
    "    clfs = []  # just to later get the median\n",
    "\n",
    "    for train, test in cv:\n",
    "        X_train, y_train = X[train], Y[train]\n",
    "        X_test, y_test = X[test], Y[test]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        clfs.append(clf)\n",
    "\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        test_score = clf.score(X_test, y_test)\n",
    "\n",
    "        train_errors.append(1 - train_score)\n",
    "        test_errors.append(1 - test_score)\n",
    "\n",
    "        scores.append(test_score)\n",
    "        proba = clf.predict_proba(X_test)\n",
    "\n",
    "        fpr, tpr, roc_thresholds = roc_curve(y_test, proba[:, 1])\n",
    "        precision, recall, pr_thresholds = precision_recall_curve(\n",
    "            y_test, proba[:, 1])\n",
    "\n",
    "        pr_scores.append(auc(recall, precision))\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        thresholds.append(pr_thresholds)\n",
    "\n",
    "    if plot:\n",
    "        scores_to_sort = pr_scores\n",
    "        median = np.argsort(scores_to_sort)[len(scores_to_sort) / 2]\n",
    "\n",
    "        plot_pr(pr_scores[median], name, phase, precisions[median],\n",
    "                recalls[median], label=name)\n",
    "\n",
    "        log_false_positives(clfs[median], X_test, y_test, name)\n",
    "\n",
    "    summary = (np.mean(scores), np.std(scores),\n",
    "               np.mean(pr_scores), np.std(pr_scores))\n",
    "    print(\"%.3f\\t%.3f\\t%.3f\\t%.3f\\t\" % summary)\n",
    "\n",
    "    return np.mean(train_errors), np.mean(test_errors)\n",
    "\n",
    "\n",
    "def print_incorrect(clf, X, Y):\n",
    "    Y_hat = clf.predict(X)\n",
    "    wrong_idx = Y_hat != Y\n",
    "    X_wrong = X[wrong_idx]\n",
    "    Y_wrong = Y[wrong_idx]\n",
    "    Y_hat_wrong = Y_hat[wrong_idx]\n",
    "    for idx in range(len(X_wrong)):\n",
    "        print(\"clf.predict('%s')=%i instead of %i\" %\n",
    "              (X_wrong[idx], Y_hat_wrong[idx], Y_wrong[idx]))\n",
    "\n",
    "\n",
    "def get_best_model():\n",
    "    best_params = dict(tfidf__ngram_range=(1, 2),\n",
    "                       tfidf__min_df=1,\n",
    "                       tfidf__stop_words=None,\n",
    "                       tfidf__smooth_idf=False,\n",
    "                       tfidf__use_idf=False,\n",
    "                       tfidf__sublinear_tf=True,\n",
    "                       tfidf__binary=False,\n",
    "                       clf__alpha=0.01,\n",
    "                       )\n",
    "\n",
    "    best_clf = create_ngram_model(best_params)\n",
    "\n",
    "    return best_clf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_orig, Y_orig = load_sanders_data()\n",
    "    classes = np.unique(Y_orig)\n",
    "    for c in classes:\n",
    "        print(\"#%s: %i\" % (c, sum(Y_orig == c)))\n",
    "\n",
    "    print(\"== Pos vs. neg ==\")\n",
    "    pos_neg = np.logical_or(Y_orig == \"positive\", Y_orig == \"negative\")\n",
    "    X = X_orig[pos_neg]\n",
    "    Y = Y_orig[pos_neg]\n",
    "    Y = tweak_labels(Y, [\"positive\"])\n",
    "    train_model(get_best_model(), X, Y, name=\"pos vs neg\", plot=True)\n",
    "\n",
    "    print(\"== Pos/neg vs. irrelevant/neutral ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"positive\", \"negative\"])\n",
    "\n",
    "    # best_clf = grid_search_model(create_union_model, X, Y, name=\"sent vs\n",
    "    # rest\", plot=True)\n",
    "    train_model(get_best_model(), X, Y, name=\"pos+neg vs rest\", plot=True)\n",
    "\n",
    "    print(\"== Pos vs. rest ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"positive\"])\n",
    "    train_model(get_best_model(), X, Y, name=\"pos vs rest\",\n",
    "                plot=True)\n",
    "\n",
    "    print(\"== Neg vs. rest ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"negative\"])\n",
    "    train_model(get_best_model(), X, Y, name=\"neg vs rest\",\n",
    "                plot=True)\n",
    "\n",
    "    print(\"time spent:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04_sent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: .\\data\\rawdata\\126131070050639874.json, error: No JSON object could be decoded\n",
      "file: .\\data\\rawdata\\126111632773480448.json, error: No JSON object could be decoded\n",
      "#irrelevant: 95\n",
      "#negative: 288\n",
      "#neutral: 609\n",
      "#positive: 194\n",
      "== Pos vs. neg ==\n",
      "0.840\t0.027\t0.895\t0.028\t\n",
      "== Pos/neg vs. irrelevant/neutral ==\n",
      "0.756\t0.011\t0.806\t0.024\t\n",
      "== Pos vs. rest ==\n",
      "0.886\t0.015\t0.677\t0.054\t\n",
      "== Neg vs. rest ==\n",
      "0.820\t0.011\t0.701\t0.048\t\n",
      "('time spent:', 60.22000002861023)\n"
     ]
    }
   ],
   "source": [
    "# This code is supporting material for the book\n",
    "# Building Machine Learning Systems with Python\n",
    "# by Willi Richert and Luis Pedro Coelho\n",
    "# published by PACKT Publishing\n",
    "#\n",
    "# It is made available under the MIT License\n",
    "\n",
    "#\n",
    "# This script trains tries to tweak hyperparameters to improve P/R AUC\n",
    "#\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "from utils import plot_pr\n",
    "from utils import load_sanders_data\n",
    "from utils import tweak_labels\n",
    "from utils import log_false_positives\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from utils import load_sent_word_net\n",
    "\n",
    "sent_word_net = load_sent_word_net()\n",
    "\n",
    "phase = \"04\"\n",
    "\n",
    "import json\n",
    "\n",
    "poscache_filename = \"poscache.json\"\n",
    "try:\n",
    "    poscache = json.load(open(poscache_filename, \"r\"))\n",
    "except IOError:\n",
    "    poscache = {}\n",
    "\n",
    "\n",
    "class LinguisticVectorizer(BaseEstimator):\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return np.array(['sent_neut', 'sent_pos', 'sent_neg',\n",
    "                         'nouns', 'adjectives', 'verbs', 'adverbs',\n",
    "                         'allcaps', 'exclamation', 'question'])\n",
    "\n",
    "    def fit(self, documents, y=None):\n",
    "        return self\n",
    "\n",
    "    def _get_sentiments(self, d):\n",
    "        # http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "        sent = tuple(nltk.word_tokenize(d))\n",
    "        if poscache is not None:\n",
    "            if d in poscache:\n",
    "                tagged = poscache[d]\n",
    "            else:\n",
    "                poscache[d] = tagged = nltk.pos_tag(sent)\n",
    "        else:\n",
    "            tagged = nltk.pos_tag(sent)\n",
    "\n",
    "        pos_vals = []\n",
    "        neg_vals = []\n",
    "\n",
    "        nouns = 0.\n",
    "        adjectives = 0.\n",
    "        verbs = 0.\n",
    "        adverbs = 0.\n",
    "\n",
    "        for w, t in tagged:\n",
    "            p, n = 0, 0\n",
    "            sent_pos_type = None\n",
    "            if t.startswith(\"NN\"):\n",
    "                sent_pos_type = \"n\"\n",
    "                nouns += 1\n",
    "            elif t.startswith(\"JJ\"):\n",
    "                sent_pos_type = \"a\"\n",
    "                adjectives += 1\n",
    "            elif t.startswith(\"VB\"):\n",
    "                sent_pos_type = \"v\"\n",
    "                verbs += 1\n",
    "            elif t.startswith(\"RB\"):\n",
    "                sent_pos_type = \"r\"\n",
    "                adverbs += 1\n",
    "\n",
    "            if sent_pos_type is not None:\n",
    "                sent_word = \"%s/%s\" % (sent_pos_type, w)\n",
    "\n",
    "                if sent_word in sent_word_net:\n",
    "                    p, n = sent_word_net[sent_word]\n",
    "\n",
    "            pos_vals.append(p)\n",
    "            neg_vals.append(n)\n",
    "\n",
    "        l = len(sent)\n",
    "        avg_pos_val = np.mean(pos_vals)\n",
    "        avg_neg_val = np.mean(neg_vals)\n",
    "\n",
    "        return [1 - avg_pos_val - avg_neg_val, avg_pos_val, avg_neg_val,\n",
    "                nouns / l, adjectives / l, verbs / l, adverbs / l]\n",
    "\n",
    "    def transform(self, documents):\n",
    "        obj_val, pos_val, neg_val, nouns, adjectives, verbs, adverbs = np.array(\n",
    "            [self._get_sentiments(d) for d in documents]).T\n",
    "\n",
    "        allcaps = []\n",
    "        exclamation = []\n",
    "        question = []\n",
    "\n",
    "        for d in documents:\n",
    "            allcaps.append(\n",
    "                np.sum([t.isupper() for t in d.split() if len(t) > 2]))\n",
    "\n",
    "            exclamation.append(d.count(\"!\"))\n",
    "            question.append(d.count(\"?\"))\n",
    "\n",
    "        result = np.array(\n",
    "            [obj_val, pos_val, neg_val, nouns, adjectives, verbs, adverbs, allcaps,\n",
    "             exclamation, question]).T\n",
    "\n",
    "        return result\n",
    "\n",
    "emo_repl = {\n",
    "    # positive emoticons\n",
    "    \"&lt;3\": \" good \",\n",
    "    \":d\": \" good \",  # :D in lower case\n",
    "    \":dd\": \" good \",  # :DD in lower case\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "\n",
    "    # negative emoticons:\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":S\": \" bad \",\n",
    "    \":-S\": \" bad \",\n",
    "}\n",
    "\n",
    "emo_repl_order = [k for (k_len, k) in reversed(\n",
    "    sorted([(len(k), k) for k in list(emo_repl.keys())]))]\n",
    "\n",
    "re_repl = {\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "}\n",
    "\n",
    "\n",
    "def create_union_model(params=None):\n",
    "    def preprocessor(tweet):\n",
    "        tweet = tweet.lower()\n",
    "\n",
    "        for k in emo_repl_order:\n",
    "            tweet = tweet.replace(k, emo_repl[k])\n",
    "        for r, repl in re_repl.items():\n",
    "            tweet = re.sub(r, repl, tweet)\n",
    "\n",
    "        return tweet.replace(\"-\", \" \").replace(\"_\", \" \")\n",
    "\n",
    "    tfidf_ngrams = TfidfVectorizer(preprocessor=preprocessor,\n",
    "                                   analyzer=\"word\")\n",
    "    ling_stats = LinguisticVectorizer()\n",
    "    all_features = FeatureUnion(\n",
    "        [('ling', ling_stats), ('tfidf', tfidf_ngrams)])\n",
    "    #all_features = FeatureUnion([('tfidf', tfidf_ngrams)])\n",
    "    #all_features = FeatureUnion([('ling', ling_stats)])\n",
    "    clf = MultinomialNB()\n",
    "    pipeline = Pipeline([('all', all_features), ('clf', clf)])\n",
    "\n",
    "    if params:\n",
    "        pipeline.set_params(**params)\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def __grid_search_model(clf_factory, X, Y):\n",
    "    cv = ShuffleSplit(\n",
    "        n=len(X), n_iter=10, test_size=0.3, random_state=0)\n",
    "\n",
    "    param_grid = dict(vect__ngram_range=[(1, 1), (1, 2), (1, 3)],\n",
    "                      vect__min_df=[1, 2],\n",
    "                      vect__smooth_idf=[False, True],\n",
    "                      vect__use_idf=[False, True],\n",
    "                      vect__sublinear_tf=[False, True],\n",
    "                      vect__binary=[False, True],\n",
    "                      clf__alpha=[0, 0.01, 0.05, 0.1, 0.5, 1],\n",
    "                      )\n",
    "\n",
    "    grid_search = GridSearchCV(clf_factory(),\n",
    "                               param_grid=param_grid,\n",
    "                               cv=cv,\n",
    "                               score_func=f1_score,\n",
    "                               verbose=10)\n",
    "    grid_search.fit(X, Y)\n",
    "    clf = grid_search.best_estimator_\n",
    "    print(clf)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_model(clf, X, Y, name=\"NB ngram\", plot=False):\n",
    "    # create it again for plotting\n",
    "    cv = ShuffleSplit(\n",
    "        n=len(X), n_iter=10, test_size=0.3, random_state=0)\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "\n",
    "    scores = []\n",
    "    pr_scores = []\n",
    "    precisions, recalls, thresholds = [], [], []\n",
    "\n",
    "    clfs = []  # just to later get the median\n",
    "\n",
    "    for train, test in cv:\n",
    "        X_train, y_train = X[train], Y[train]\n",
    "        X_test, y_test = X[test], Y[test]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        clfs.append(clf)\n",
    "\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        test_score = clf.score(X_test, y_test)\n",
    "\n",
    "        train_errors.append(1 - train_score)\n",
    "        test_errors.append(1 - test_score)\n",
    "\n",
    "        scores.append(test_score)\n",
    "        proba = clf.predict_proba(X_test)\n",
    "\n",
    "        fpr, tpr, roc_thresholds = roc_curve(y_test, proba[:, 1])\n",
    "        precision, recall, pr_thresholds = precision_recall_curve(\n",
    "            y_test, proba[:, 1])\n",
    "\n",
    "        pr_scores.append(auc(recall, precision))\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        thresholds.append(pr_thresholds)\n",
    "\n",
    "    if plot:\n",
    "        scores_to_sort = pr_scores\n",
    "        median = np.argsort(scores_to_sort)[len(scores_to_sort) / 2]\n",
    "\n",
    "        plot_pr(pr_scores[median], name, phase, precisions[median],\n",
    "                recalls[median], label=name)\n",
    "\n",
    "        log_false_positives(clfs[median], X_test, y_test, name)\n",
    "\n",
    "    summary = (np.mean(scores), np.std(scores),\n",
    "               np.mean(pr_scores), np.std(pr_scores))\n",
    "    print(\"%.3f\\t%.3f\\t%.3f\\t%.3f\\t\" % summary)\n",
    "\n",
    "    return np.mean(train_errors), np.mean(test_errors)\n",
    "\n",
    "\n",
    "def print_incorrect(clf, X, Y):\n",
    "    Y_hat = clf.predict(X)\n",
    "    wrong_idx = Y_hat != Y\n",
    "    X_wrong = X[wrong_idx]\n",
    "    Y_wrong = Y[wrong_idx]\n",
    "    Y_hat_wrong = Y_hat[wrong_idx]\n",
    "    for idx in range(len(X_wrong)):\n",
    "        print(\"clf.predict('%s')=%i instead of %i\" %\n",
    "              (X_wrong[idx], Y_hat_wrong[idx], Y_wrong[idx]))\n",
    "\n",
    "\n",
    "def get_best_model():\n",
    "    best_params = dict(all__tfidf__ngram_range=(1, 2),\n",
    "                       all__tfidf__min_df=1,\n",
    "                       all__tfidf__stop_words=None,\n",
    "                       all__tfidf__smooth_idf=False,\n",
    "                       all__tfidf__use_idf=False,\n",
    "                       all__tfidf__sublinear_tf=True,\n",
    "                       all__tfidf__binary=False,\n",
    "                       clf__alpha=0.01,\n",
    "                       )\n",
    "\n",
    "    best_clf = create_union_model(best_params)\n",
    "\n",
    "    return best_clf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_orig, Y_orig = load_sanders_data()\n",
    "    #from sklearn.utils import shuffle\n",
    "    # print \"shuffle, sample\"\n",
    "    #X_orig, Y_orig = shuffle(X_orig, Y_orig)\n",
    "    #X_orig = X_orig[:100,]\n",
    "    #Y_orig = Y_orig[:100,]\n",
    "    classes = np.unique(Y_orig)\n",
    "    for c in classes:\n",
    "        print(\"#%s: %i\" % (c, sum(Y_orig == c)))\n",
    "\n",
    "    print(\"== Pos vs. neg ==\")\n",
    "    pos_neg = np.logical_or(Y_orig == \"positive\", Y_orig == \"negative\")\n",
    "    X = X_orig[pos_neg]\n",
    "    Y = Y_orig[pos_neg]\n",
    "    Y = tweak_labels(Y, [\"positive\"])\n",
    "    train_model(get_best_model(), X, Y, name=\"pos vs neg\", plot=True)\n",
    "\n",
    "    print(\"== Pos/neg vs. irrelevant/neutral ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"positive\", \"negative\"])\n",
    "\n",
    "    # best_clf = grid_search_model(create_union_model, X, Y, name=\"sent vs\n",
    "    # rest\", plot=True)\n",
    "    train_model(get_best_model(), X, Y, name=\"pos+neg vs rest\", plot=True)\n",
    "\n",
    "    print(\"== Pos vs. rest ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"positive\"])\n",
    "    train_model(get_best_model(), X, Y, name=\"pos vs rest\",\n",
    "                plot=True)\n",
    "\n",
    "    print(\"== Neg vs. rest ==\")\n",
    "    X = X_orig\n",
    "    Y = tweak_labels(Y_orig, [\"negative\"])\n",
    "    train_model(get_best_model(), X, Y, name=\"neg vs rest\",\n",
    "                plot=True)\n",
    "\n",
    "    print(\"time spent:\", time.time() - start_time)\n",
    "\n",
    "    json.dump(poscache, open(poscache_filename, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
